<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/blog/styles.11257aa1b3709491b690.css">@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:100;src:local("Raleway Thin "),local("Raleway-Thin"),url(/blog/static/raleway-latin-100-2d7a1238fea2c2307507a59e0855ff42.woff2) format("woff2"),url(/blog/static/raleway-latin-100-161ab2ad00fa982f54cb8f16f26a0af3.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:100;src:local("Raleway Thin italic"),local("Raleway-Thinitalic"),url(/blog/static/raleway-latin-100italic-9f282cbf5d76bdef157069c79fcf5e2e.woff2) format("woff2"),url(/blog/static/raleway-latin-100italic-5b062a0e5a1a615b73c3d0be017d2e52.woff) format("woff")}@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:200;src:local("Raleway Extra Light "),local("Raleway-Extra Light"),url(/blog/static/raleway-latin-200-3fef5ebed6aa72326bf742645ba8a331.woff2) format("woff2"),url(/blog/static/raleway-latin-200-138feb2449027da5ec661144f6ef2c82.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:200;src:local("Raleway Extra Light italic"),local("Raleway-Extra Lightitalic"),url(/blog/static/raleway-latin-200italic-33855fc8800ac209c24e93b171b90784.woff2) format("woff2"),url(/blog/static/raleway-latin-200italic-cc400d950a3bacf5b5fce27fb7c0555b.woff) format("woff")}@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:300;src:local("Raleway Light "),local("Raleway-Light"),url(/blog/static/raleway-latin-300-d724dad2e61905f488d048e51d45ae3e.woff2) format("woff2"),url(/blog/static/raleway-latin-300-4baae0f7033718fc7a7a6dbb301db7cc.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:300;src:local("Raleway Light italic"),local("Raleway-Lightitalic"),url(/blog/static/raleway-latin-300italic-72abfd8df65a5440b9f9ad0fb37413bd.woff2) format("woff2"),url(/blog/static/raleway-latin-300italic-4f9a9bcce1b9039228b803f4fd7af4a6.woff) format("woff")}@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:400;src:local("Raleway Regular "),local("Raleway-Regular"),url(/blog/static/raleway-latin-400-43c849ea0258ce0d23a480e840881f16.woff2) format("woff2"),url(/blog/static/raleway-latin-400-60b344eb8dd676754364fc5ae4500d62.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:400;src:local("Raleway Regular italic"),local("Raleway-Regularitalic"),url(/blog/static/raleway-latin-400italic-9d182d98e01325f30dee06e58c385c1a.woff2) format("woff2"),url(/blog/static/raleway-latin-400italic-16b1681946ff1ae64f10059518f0f4b8.woff) format("woff")}@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:500;src:local("Raleway Medium "),local("Raleway-Medium"),url(/blog/static/raleway-latin-500-6a9b9c422e662a18013ee064fd789213.woff2) format("woff2"),url(/blog/static/raleway-latin-500-e9163c03fd8b6ada4fd3cf87dbc7e2ae.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:500;src:local("Raleway Medium italic"),local("Raleway-Mediumitalic"),url(/blog/static/raleway-latin-500italic-3ffdda0b3d57c6a3ccfc61960ac10934.woff2) format("woff2"),url(/blog/static/raleway-latin-500italic-20ee2c52d2e06b53d5c90d1dafcf5026.woff) format("woff")}@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:600;src:local("Raleway SemiBold "),local("Raleway-SemiBold"),url(/blog/static/raleway-latin-600-911d926608ce81ca8d62e74b7d09d276.woff2) format("woff2"),url(/blog/static/raleway-latin-600-b2b7ca0eaed5270531d7a447725203b9.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:600;src:local("Raleway SemiBold italic"),local("Raleway-SemiBolditalic"),url(/blog/static/raleway-latin-600italic-b121e5d74dbfca5940fa38c9506581a6.woff2) format("woff2"),url(/blog/static/raleway-latin-600italic-7d9764eff10e7bfd87a3de44a132eaa6.woff) format("woff")}@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:700;src:local("Raleway Bold "),local("Raleway-Bold"),url(/blog/static/raleway-latin-700-77d77f36bed0a452984832f6b5f22e3f.woff2) format("woff2"),url(/blog/static/raleway-latin-700-f252da3726243df4163d7af11448fed1.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:700;src:local("Raleway Bold italic"),local("Raleway-Bolditalic"),url(/blog/static/raleway-latin-700italic-33ecb99651d19f0230f36cd6191cbf32.woff2) format("woff2"),url(/blog/static/raleway-latin-700italic-e79e0f8f3d8581470f83635fef562668.woff) format("woff")}@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:800;src:local("Raleway ExtraBold "),local("Raleway-ExtraBold"),url(/blog/static/raleway-latin-800-7222f1fa6b1ba32e4010040ff1c5ee7f.woff2) format("woff2"),url(/blog/static/raleway-latin-800-47f455f9e7eaacb6c1efd0456b9898f9.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:800;src:local("Raleway ExtraBold italic"),local("Raleway-ExtraBolditalic"),url(/blog/static/raleway-latin-800italic-a45bb915945f4eca1f36a3788ebe9a2b.woff2) format("woff2"),url(/blog/static/raleway-latin-800italic-675a7d7a777a9a07f2b10083a2a023d2.woff) format("woff")}@font-face{font-family:Raleway;font-style:normal;font-display:swap;font-weight:900;src:local("Raleway Black "),local("Raleway-Black"),url(/blog/static/raleway-latin-900-d64bf57c79aa2e0c95705017b2867a00.woff2) format("woff2"),url(/blog/static/raleway-latin-900-d04db131ad975034bf42527e9f5ecd9c.woff) format("woff")}@font-face{font-family:Raleway;font-style:italic;font-display:swap;font-weight:900;src:local("Raleway Black italic"),local("Raleway-Blackitalic"),url(/blog/static/raleway-latin-900italic-c1c435205dc2536acd219dad5c2e9634.woff2) format("woff2"),url(/blog/static/raleway-latin-900italic-b2eea53568120d184375076e84decc61.woff) format("woff")}</style><meta name="generator" content="Gatsby 2.21.0"/><title data-react-helmet="true"></title><style data-styled="" data-styled-version="5.1.0"></style><link rel="sitemap" type="application/xml" href="/blog/sitemap.xml"/><link rel="icon" href="/blog/favicon-32x32.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="manifest" href="/blog/manifest.webmanifest"/><meta name="theme-color" content="#50E3C2"/><link rel="apple-touch-icon" sizes="48x48" href="/blog/icons/icon-48x48.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="apple-touch-icon" sizes="72x72" href="/blog/icons/icon-72x72.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="apple-touch-icon" sizes="96x96" href="/blog/icons/icon-96x96.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="apple-touch-icon" sizes="144x144" href="/blog/icons/icon-144x144.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="apple-touch-icon" sizes="192x192" href="/blog/icons/icon-192x192.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="apple-touch-icon" sizes="256x256" href="/blog/icons/icon-256x256.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="apple-touch-icon" sizes="384x384" href="/blog/icons/icon-384x384.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="apple-touch-icon" sizes="512x512" href="/blog/icons/icon-512x512.png?v=266b11ea980cf4fdac1adda3f06a985b"/><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><link as="script" rel="preload" href="/blog/webpack-runtime-7c6f938b0d4f2aceb229.js"/><link as="script" rel="preload" href="/blog/framework-34fd78e4db8762054a7b.js"/><link as="script" rel="preload" href="/blog/styles-3d55a950c42f3ec6b7c7.js"/><link as="script" rel="preload" href="/blog/05d954cf-17e5402c80a99dca571a.js"/><link as="script" rel="preload" href="/blog/app-1c043eea9616e75bd71c.js"/><link as="script" rel="preload" href="/blog/component---src-pages-posts-10-02-2021-learning-index-mdx-b81190d2cb678307a0e5.js"/><link as="fetch" rel="preload" href="/blog/page-data/posts/10-02-2021-learning/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/blog/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><main style="opacity:0"><p>From the previous blogs, we know basically how a machine will make predictions. So obviously, the next question is how will a machine improve the prediction it
makes, how will the prediction be more accurate? This is where we will understand how a machine learns, or in a more technical way, how the algorithm will update
the weights to give a better output. </p><p>In a previous blog, I mentioned the three basic steps of how machine learning works are predicting, comparing and learning. Let‚Äôs dive into the comparing and
learning parts now. </p><h2>üìä Comparing</h2><p>After predicting an output, we need to measure how close the output was to the correct answer. Only once we know by how much did our measurement miss, will we
be able to ‚Äúlearn‚Äù where we went wrong. </p><p>For this, we find out the error between the prediction and the true output. The simplest way to find this error is to subtract the input from the output and see
by what margin we were off. </p><h2>üìà Learning</h2><p>After comparison, the final step is learning which updates the  weights in a network to make better predictions. In this  blog, we will consider a learning
algorithm called Gradient Descent.</p><h2>üéØ Finding the error</h2><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">weight <span class="token operator">=</span> <span class="token number">0.5</span>
<span class="token builtin">input</span> <span class="token operator">=</span> <span class="token number">0.3</span>
goal <span class="token operator">=</span> <span class="token number">1</span>

pred <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">*</span> weight

error <span class="token operator">=</span> <span class="token punctuation">(</span>goal <span class="token operator">-</span> pred<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>error<span class="token punctuation">)</span></code></pre></div><p>Output: </p><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">0.7224999999999999</code></pre></div><p>Here we calculated the difference between the prediction made and the goal, and then squared it. This is called the mean squared error. This is one of the
techniques using which we can find the error. There‚Äôll be a couple of questions coming up about now.</p><p><strong>Why did we square the error?</strong></p><p>We want the error to be positive, and hence we square it. Simply finding the difference between <code class="language-text">goal</code> and <code class="language-text">pred</code> might sometimes give a negative result.</p><p><strong>Why do we need the error to be positive?</strong></p><p>Let‚Äôs say you‚Äôre practising target shooting. Whether your bullet hits the target 2 centimetres above, or 2 centimetres below, both the times, you missed by 2
centimetres. In both the cases your error is 2 centimetres. Now instead of squaring if you just find the error, the error will be 2 centimetres, and -2
centimeters, thereby making the resultant average of the error 0(<code class="language-text">2 + (-2) = 0</code>). This will give us a wrong result. Therefore to include the entire range, we
keep the error positive by squaring it. </p><p>One thing to note here is: Squaring will make big errors bigger, and small errors, -1 &lt; error &lt; 1, smaller. But this works fine because we will be able to
penalise bigger errors better, instead of worrying about the small ones. </p><h2>üìâ Gradient descent</h2><p>So now let‚Äôs get into gradient descent. Imagine you are in a valley. You need to get to the bottom of the valley by taking small steps at a time. If your steps
are too large, you‚Äôll end up crossing the bottom, and if your steps are too small it‚Äôll take you forever to get to the bottom. The algorithm which will help you
get to the bottom efficiently is gradient descent. </p><p><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1174px">
      <a class="gatsby-resp-image-link" href="/blog/static/9b0e1d17b2e6fa5c1655be510303d25f/04784/gd.png" style="display:block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:87.74703557312253%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAIAAADUsmlHAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABMklEQVQ4y52TaW6EMAyFuf9N+M8lOAFBQiAIy5R936F9rSkwlDJoLIGCyBfb7znCPM9933++FcI4jkVR3AeQbIN932+a5iaJTNi/HiEEQZBl2X3YcZwNruvadd1DPf9FVVVRFG1wnue2bb+E6W8YhiTQAmuaZlnWm7BhGOCHYbijs+d50zRtakMwZEYzL2GMw0EdAU8cxzjyovK1ZvJlg1EGPmRZvuYRMAlWPU0YdSuKoiRJ5ORpWuTcj8cC46PrOqxM02zb9jQ5ToSdf8/9LhsBMbhlcc6J3L8R6Oh0ChfBdF0vyzJNU5tzamTlQWLD+a0iGZmiBL6PwpAB+WG+qqpoBOskSejaDj8BU1erhX0SwLT+eDxUxtAneQFm/A3o8uTzQSTswNgoisIYa5v2Ymy+ANkhHqSmdsUiAAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <picture>
        <source srcSet="/blog/static/9b0e1d17b2e6fa5c1655be510303d25f/6b97b/gd.webp 506w,/blog/static/9b0e1d17b2e6fa5c1655be510303d25f/2dbb9/gd.webp 1012w,/blog/static/9b0e1d17b2e6fa5c1655be510303d25f/963af/gd.webp 1174w" sizes="(max-width: 1174px) 100vw, 1174px" type="image/webp"/>
        <source srcSet="/blog/static/9b0e1d17b2e6fa5c1655be510303d25f/29f4e/gd.png 506w,/blog/static/9b0e1d17b2e6fa5c1655be510303d25f/ad997/gd.png 1012w,/blog/static/9b0e1d17b2e6fa5c1655be510303d25f/04784/gd.png 1174w" sizes="(max-width: 1174px) 100vw, 1174px" type="image/png"/>
        <img class="gatsby-resp-image-image" src="/blog/static/9b0e1d17b2e6fa5c1655be510303d25f/04784/gd.png" alt="gd" title="gd" loading="lazy" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0"/>
      </picture>
  </a>
    </span></p><p>We are currently at the black dot, and we want to get to the dotted circle, which is the bottom.   </p><p>The basic rule of machine learning: We need to keep adjusting the weights so that the error reduces to 0.</p><p>Let‚Äôs see the code for a basic implementation of gradient descent: </p><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">weight<span class="token punctuation">,</span> goal_pred<span class="token punctuation">,</span> <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.1</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> iteration <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;-----\nWeight:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
	pred <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">*</span> weight
	error <span class="token operator">=</span> <span class="token punctuation">(</span>pred <span class="token operator">-</span> goal_pred<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
	delta <span class="token operator">=</span> pred <span class="token operator">-</span> goal_pred
	weight_delta <span class="token operator">=</span> delta <span class="token operator">*</span> <span class="token builtin">input</span>
	weight <span class="token operator">=</span> weight <span class="token operator">-</span> weight_delta
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Error:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>error<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot; Prediction:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Delta:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>delta<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot; Weight Delta:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>weight_delta<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div><p>Output: </p><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">-----
Weight:0.0
Error:0.25 Prediction:0.0
Delta:-0.5 Weight Delta:-0.55
-----
Weight:0.55
Error:0.01102500000000002 Prediction:0.6050000000000001
Delta:0.1050000000000001 Weight Delta:0.11550000000000012
-----
Weight:0.43449999999999994
Error:0.00048620250000000064 Prediction:0.47795
Delta:-0.022050000000000014 Weight Delta:-0.024255000000000016
-----
Weight:0.45875499999999997
Error:2.1441530249999833e-05 Prediction:0.5046305
Delta:0.004630499999999982 Weight Delta:0.0050935499999999806</code></pre></div><p><strong>What does each variable do here?</strong></p><table><thead><tr><th>pred</th><th>The prediction made by the network</th></tr></thead><tbody><tr><td>error</td><td>The mean squared error</td></tr><tr><td>delta</td><td>The absolute error with it‚Äôs sign</td></tr><tr><td>weight_delta</td><td>Calculating the amount by which the weights need to be changed along with the direction (positive or negative, increase or decrease)</td></tr></tbody></table><p>Here we calculated the <code class="language-text">weight_delta</code> by multiplying the delta with the input. The reason for this is so that the change to be made in the weights can be scaled.
Basically, if the input is big, the amount by which we change the weight should also be big.</p><p>This is the simplest implementation of gradient descent in which we: </p><ul><li>Find the prediction</li><li>Find the mean squared error</li><li>Find the absolute error</li><li>Find the amount by which the weight needs to be updates</li><li>Update the weight</li></ul><p>As we keep improving the algorithm, the underlying steps will still follow the same principles. </p><p>Let‚Äôs dig deeper into <code class="language-text">weight_delta</code> before we proceed further. <code class="language-text">weight_delta</code> is a derivative. A derivative simply allows us to pick a couple of variables in a
formula and figure out how they relate to each other. Here, <code class="language-text">weight_delta</code> is what is determining the relation between the <code class="language-text">error</code> and the <code class="language-text">weight</code>. Our
derivative, <code class="language-text">weight_delta</code> tells how much did changing a weight contribute to the error. </p><table><thead><tr><th><img src="https://user-images.githubusercontent.com/41234408/107554978-a343eb00-6bfc-11eb-97f5-1a3669ca8154.gif" alt="gd2"/></th></tr></thead><tbody><tr><td>How gradient descent reaches the bottom</td></tr></tbody></table><p>Now, in the algorithm we ran, try to set the <code class="language-text">goal_pred</code> variable to 4.</p><p>Output: </p><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">-----
Weight:0.0
Error:0.25 Prediction:0.0
Delta:-0.5 Weight Delta:-2.0
-----
Weight:2.0
Error:56.25 Prediction:8.0
Delta:7.5 Weight Delta:30.0
-----
Weight:-28.0
Error:12656.25 Prediction:-112.0
Delta:-112.5 Weight Delta:-450.0
-----
Weight:422.0
Error:2847656.25 Prediction:1688.0
Delta:1687.5 Weight Delta:6750.0</code></pre></div><p>The output is not even remotely close to 2, and the error just kept on increasing. The reason for this is they way we are updating the weights. </p><p><code class="language-text">weight = weight - (input * (pred - goal_pred))</code></p><p>The larger, the input, the larger the update to the weight. The network will start overcorrecting in both directions in order to compensate for the error. </p><p>Imagine you‚Äôre blindfolded and are jumping down a mountain in small jumps to get to the bottom. So you keep taking small jumps. In case of this current
scenario, let‚Äôs assume you miss the bottom, and jump up to the other side which starts going up. You know now that you‚Äôve crossed the bottom since you‚Äôre going
further away from your goal. So now in order to take a step back, you jump in the reverse direction. But since your input is already big, it‚Äôll result in your
jump taking you back up to the other side of the mountain. This will keep continuing, the error increasing, and you going further away from the bottom.</p><p>This is known as divergence. </p><h2>ü§º‚Äç‚ôÇÔ∏è How to combat divergence?</h2><p>Now that we know where our algorithm lacks, we need to improve it. The error is basically that the network is overshooting. What if we could simply multiply the
weight update by a small number which compensates for this overshooting? This way, we would be taking smaller steps instead of jumping here and there.</p><p>For this purpose, we use a variable called alpha. The alpha value generally ranges between 0 and 1. <code class="language-text">alpha</code> is something which we need to find out, mostly by
guesswork(there are more elegant solutions to this than guesswork which we can get to later). We can try out different values of alpha ranging between 0 and 1,
like 0.1, 0.01, 0.001, etc, and keep on adjusting it until we feel the value is optimal and there won‚Äôt be any major overshooting. </p><p>So we will simply multiply our derivative with alpha. Let‚Äôs take a look at the updated code which includes <code class="language-text">alpha</code> as well.</p><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">weight<span class="token punctuation">,</span> goal_pred<span class="token punctuation">,</span> <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
alpha <span class="token operator">=</span> <span class="token number">0.1</span>

<span class="token keyword">for</span> iteration <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;-----\nWeight:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
	pred <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">*</span> weight
	error <span class="token operator">=</span> <span class="token punctuation">(</span>pred <span class="token operator">-</span> goal_pred<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
	delta <span class="token operator">=</span> pred <span class="token operator">-</span> goal_pred
	weight_delta <span class="token operator">=</span> delta <span class="token operator">*</span> <span class="token builtin">input</span>
	weight <span class="token operator">=</span> weight <span class="token operator">-</span> <span class="token punctuation">(</span>alpha <span class="token operator">*</span> weight_delta<span class="token punctuation">)</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Error:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>error<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot; Prediction:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Delta:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>delta<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot; Weight Delta:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>weight_delta<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>Output: </p><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">-----
Weight:0.0
Error:0.25 Prediction:0.0
Delta:-0.5 Weight Delta:-2.0
-----
Weight:0.2
Error:0.09000000000000002 Prediction:0.8
Delta:0.30000000000000004 Weight Delta:1.2000000000000002
-----
Weight:0.07999999999999999
Error:0.03240000000000002 Prediction:0.31999999999999995
Delta:-0.18000000000000005 Weight Delta:-0.7200000000000002
-----
Weight:0.15200000000000002
Error:0.011664000000000022 Prediction:0.6080000000000001
Delta:0.1080000000000001 Weight Delta:0.4320000000000004</code></pre></div><p>The output is now a lot closer to 0.5, than what it was before. This means we‚Äôre on the correct track. Now we can just increase the number of iterations from 4
to 20 in order to get the desired result. </p><div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">weight<span class="token punctuation">,</span> goal_pred<span class="token punctuation">,</span> <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
alpha <span class="token operator">=</span> <span class="token number">0.1</span>

<span class="token keyword">for</span> iteration <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;-----\nWeight:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
	pred <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">*</span> weight
	error <span class="token operator">=</span> <span class="token punctuation">(</span>pred <span class="token operator">-</span> goal_pred<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
	delta <span class="token operator">=</span> pred <span class="token operator">-</span> goal_pred
	weight_delta <span class="token operator">=</span> delta <span class="token operator">*</span> <span class="token builtin">input</span>
	weight <span class="token operator">=</span> weight <span class="token operator">-</span> <span class="token punctuation">(</span>alpha <span class="token operator">*</span> weight_delta<span class="token punctuation">)</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Error:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>error<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot; Prediction:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Delta:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>delta<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot; Weight Delta:&quot;</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>weight_delta<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>Output: </p><div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">-----
Weight:0.0
Error:0.25 Prediction:0.0
Delta:-0.5 Weight Delta:-2.0
-----
Weight:0.2
Error:0.09000000000000002 Prediction:0.8
Delta:0.30000000000000004 Weight Delta:1.2000000000000002
-----
Weight:0.07999999999999999
Error:0.03240000000000002 Prediction:0.31999999999999995
Delta:-0.18000000000000005 Weight Delta:-0.7200000000000002
-----

.
.
.
.
Weight:0.1249647361261568
Error:1.9896652774865827e-08 Prediction:0.4998589445046272
Delta:-0.00014105549537279938 Weight Delta:-0.0005642219814911975
-----
Weight:0.1250211583243059
Error:7.16279499894418e-09 Prediction:0.5000846332972236
Delta:8.463329722363522e-05 Weight Delta:0.00033853318889454087
-----
Weight:0.12498730500541645
Error:2.5786061996210327e-09 Prediction:0.4999492200216658
Delta:-5.077997833419223e-05 Weight Delta:-0.00020311991333676893
-----
Weight:0.12500761699675011
Error:9.282982318601891e-10 Prediction:0.5000304679870005
Delta:3.046798700045983e-05 Weight Delta:0.00012187194800183931</code></pre></div><p>We got to the output, 0.5000304679870005 which is almost equal to 0.5 and the error is almost negligible now. </p><p>So this is basically how gradient descent works under the hood and how machines can learn. In the next blog, we will play with gradient descent a bit more,
learn to use it with multiple inputs, outputs, and tweak some aspects of the weights to get better results. </p></main></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-166796928-1', 'auto', {});
      
      
      
      
      
      }</script><script>
  
  
  if(true) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-134206784-1', 'auto', {});
      
      
      
      
      
      }</script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/posts/10-02-2021-learning/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-1c043eea9616e75bd71c.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-b83f235b372d5fabfbee.js"],"component---src-pages-404-js":["/component---src-pages-404-js-773a61352e8c84361224.js"],"component---src-pages-blog-js":["/component---src-pages-blog-js-9516c8dabc285618f7df.js"],"component---src-pages-home-home-js":["/component---src-pages-home-home-js-0d0fc9cae17ff1e2a678.js"],"component---src-pages-home-index-js":["/component---src-pages-home-index-js-bad923196cf95a0cc428.js"],"component---src-pages-index-js":["/component---src-pages-index-js-2f30e1940f2019e032be.js"],"component---src-pages-me-about-me-js":["/component---src-pages-me-about-me-js-72723e291dee7a7a394f.js"],"component---src-pages-me-index-js":["/component---src-pages-me-index-js-c82126aef8132629708b.js"],"component---src-pages-posts-01-01-2021-mlh-fellowship-sprint-5-index-mdx":["/component---src-pages-posts-01-01-2021-mlh-fellowship-sprint-5-index-mdx-76156d94b72796b99627.js"],"component---src-pages-posts-02-07-2020-periodo-de-codificacion-uno-index-mdx":["/component---src-pages-posts-02-07-2020-periodo-de-codificacion-uno-index-mdx-e8cd71bbf1062a9dd084.js"],"component---src-pages-posts-02-08-2020-periodo-de-codificacion-dos-index-mdx":["/component---src-pages-posts-02-08-2020-periodo-de-codificacion-dos-index-mdx-a1a81d6cec9558e4a7f5.js"],"component---src-pages-posts-04-01-2021-mlh-fellowship-sprint-6-index-mdx":["/component---src-pages-posts-04-01-2021-mlh-fellowship-sprint-6-index-mdx-02b9f6b3f3e35ade39b0.js"],"component---src-pages-posts-10-02-2021-learning-index-mdx":["/component---src-pages-posts-10-02-2021-learning-index-mdx-b81190d2cb678307a0e5.js"],"component---src-pages-posts-14-01-2019-kwoc-end-report-index-mdx":["/component---src-pages-posts-14-01-2019-kwoc-end-report-index-mdx-4834b878d12f0acc3f46.js"],"component---src-pages-posts-14-01-2021-mlh-fellowship-graduation-index-mdx":["/component---src-pages-posts-14-01-2021-mlh-fellowship-graduation-index-mdx-5ac840f2a72121351bae.js"],"component---src-pages-posts-14-11-2020-mlh-fellowship-sprint-3-index-mdx":["/component---src-pages-posts-14-11-2020-mlh-fellowship-sprint-3-index-mdx-d142c9e57de1d31406e0.js"],"component---src-pages-posts-16-10-2020-mlh-fellowship-sprint-1-index-mdx":["/component---src-pages-posts-16-10-2020-mlh-fellowship-sprint-1-index-mdx-152803386d73a6627d1c.js"],"component---src-pages-posts-17-02-2019-collaboration-with-git-index-mdx":["/component---src-pages-posts-17-02-2019-collaboration-with-git-index-mdx-21185e4e4e500e7f4140.js"],"component---src-pages-posts-17-09-2018-collaborating-with-git-index-mdx":["/component---src-pages-posts-17-09-2018-collaborating-with-git-index-mdx-9d8e26b6e44113c8f5c7.js"],"component---src-pages-posts-18-08-2020-ai-singapore-summer-school-index-mdx":["/component---src-pages-posts-18-08-2020-ai-singapore-summer-school-index-mdx-c2928ba0944081249eca.js"],"component---src-pages-posts-20-12-2018-coffee-ordering-app-index-mdx":["/component---src-pages-posts-20-12-2018-coffee-ordering-app-index-mdx-364f62a5a55baee66b17.js"],"component---src-pages-posts-21-01-2021-how-to-teach-machines-index-mdx":["/component---src-pages-posts-21-01-2021-how-to-teach-machines-index-mdx-73e3db6bf265f61f3f8e.js"],"component---src-pages-posts-21-09-2020-hackmit-2020-index-mdx":["/component---src-pages-posts-21-09-2020-hackmit-2020-index-mdx-8559e43d98cde5437d9b.js"],"component---src-pages-posts-22-01-2021-prediction-1-index-mdx":["/component---src-pages-posts-22-01-2021-prediction-1-index-mdx-8e15b3b5991ae6a96e70.js"],"component---src-pages-posts-22-09-2020-mlh-fellowship-fall-2020-acceptance-index-mdx":["/component---src-pages-posts-22-09-2020-mlh-fellowship-fall-2020-acceptance-index-mdx-a7a8059f7ba7d9944e68.js"],"component---src-pages-posts-29-08-2020-periodo-de-codificacion-tres-index-mdx":["/component---src-pages-posts-29-08-2020-periodo-de-codificacion-tres-index-mdx-33ab922f7d0b03645b15.js"],"component---src-pages-posts-29-10-2020-mlh-fellowship-sprint-2-index-mdx":["/component---src-pages-posts-29-10-2020-mlh-fellowship-sprint-2-index-mdx-1913cb2fe3853cfabe3e.js"],"component---src-pages-posts-29-11-2020-mlh-fellowship-sprint-4-index-mdx":["/component---src-pages-posts-29-11-2020-mlh-fellowship-sprint-4-index-mdx-200bbb7414d02e816ace.js"],"component---src-pages-posts-30-01-2021-prediction-2-index-mdx":["/component---src-pages-posts-30-01-2021-prediction-2-index-mdx-8efba32d0be805fb2720.js"],"component---src-pages-posts-30-08-2020-resumen-del-trabajo-realizado-index-mdx":["/component---src-pages-posts-30-08-2020-resumen-del-trabajo-realizado-index-mdx-52336426ea1cd6cf8c80.js"],"component---src-pages-posts-31-05-2020-periodo-de-union-comunitaria-index-mdx":["/component---src-pages-posts-31-05-2020-periodo-de-union-comunitaria-index-mdx-de7e8bbb9dcbdc352000.js"],"component---src-templates-blog-post-blog-post-js":["/component---src-templates-blog-post-blog-post-js-ba06e4b89595178d66f3.js"],"WorldMap":["/WorldMap-2dccafdf2801462d37f3.js"]};/*]]>*/</script><script src="/blog/component---src-pages-posts-10-02-2021-learning-index-mdx-b81190d2cb678307a0e5.js" async=""></script><script src="/blog/app-1c043eea9616e75bd71c.js" async=""></script><script src="/blog/05d954cf-17e5402c80a99dca571a.js" async=""></script><script src="/blog/styles-3d55a950c42f3ec6b7c7.js" async=""></script><script src="/blog/framework-34fd78e4db8762054a7b.js" async=""></script><script src="/blog/webpack-runtime-7c6f938b0d4f2aceb229.js" async=""></script></body></html>